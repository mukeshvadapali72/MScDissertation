{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('fashionblogs1.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fashiontext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fashionspotcontent</th>\n",
       "      <td>\"There are certain staples every wardrobe need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>justthedesign</th>\n",
       "      <td>Our Reasons To Give Into The Embroidery Trend ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mariecuriefashiontext</th>\n",
       "      <td>https://www.marieclaire.co.uk/fashion/build-a-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refinery29</th>\n",
       "      <td>Velvet material was seen all over the fall run...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vogueIndia</th>\n",
       "      <td>5 designer labels you will always find in alia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voguefashiontext</th>\n",
       "      <td>//www.vogue.co.uk//fashion/article/guide-to-b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             fashiontext\n",
       "fashionspotcontent     \"There are certain staples every wardrobe need...\n",
       "justthedesign          Our Reasons To Give Into The Embroidery Trend ...\n",
       "mariecuriefashiontext  https://www.marieclaire.co.uk/fashion/build-a-...\n",
       "refinery29             Velvet material was seen all over the fall run...\n",
       "vogueIndia             5 designer labels you will always find in alia...\n",
       "voguefashiontext        //www.vogue.co.uk//fashion/article/guide-to-b..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis: To get quick overview of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fashiontext</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fashionspotcontent</th>\n",
       "      <td>\"There are certain staples every wardrobe need...</td>\n",
       "      <td>1989129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>justthedesign</th>\n",
       "      <td>Our Reasons To Give Into The Embroidery Trend ...</td>\n",
       "      <td>6289320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mariecuriefashiontext</th>\n",
       "      <td>https://www.marieclaire.co.uk/fashion/build-a-...</td>\n",
       "      <td>604003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refinery29</th>\n",
       "      <td>Velvet material was seen all over the fall run...</td>\n",
       "      <td>1999745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vogueIndia</th>\n",
       "      <td>5 designer labels you will always find in alia...</td>\n",
       "      <td>6691634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             fashiontext  \\\n",
       "fashionspotcontent     \"There are certain staples every wardrobe need...   \n",
       "justthedesign          Our Reasons To Give Into The Embroidery Trend ...   \n",
       "mariecuriefashiontext  https://www.marieclaire.co.uk/fashion/build-a-...   \n",
       "refinery29             Velvet material was seen all over the fall run...   \n",
       "vogueIndia             5 designer labels you will always find in alia...   \n",
       "\n",
       "                       char_count  \n",
       "fashionspotcontent        1989129  \n",
       "justthedesign             6289320  \n",
       "mariecuriefashiontext      604003  \n",
       "refinery29                1999745  \n",
       "vogueIndia                6691634  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['char_count'] = data_df['fashiontext'].str.len() ## this also includes spaces\n",
    "data_df[['fashiontext','char_count']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate average word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fashiontext</th>\n",
       "      <th>avg_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fashionspotcontent</th>\n",
       "      <td>\"There are certain staples every wardrobe need...</td>\n",
       "      <td>5.936963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>justthedesign</th>\n",
       "      <td>Our Reasons To Give Into The Embroidery Trend ...</td>\n",
       "      <td>4.988989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mariecuriefashiontext</th>\n",
       "      <td>https://www.marieclaire.co.uk/fashion/build-a-...</td>\n",
       "      <td>5.025445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refinery29</th>\n",
       "      <td>Velvet material was seen all over the fall run...</td>\n",
       "      <td>5.429397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vogueIndia</th>\n",
       "      <td>5 designer labels you will always find in alia...</td>\n",
       "      <td>4.941884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             fashiontext  \\\n",
       "fashionspotcontent     \"There are certain staples every wardrobe need...   \n",
       "justthedesign          Our Reasons To Give Into The Embroidery Trend ...   \n",
       "mariecuriefashiontext  https://www.marieclaire.co.uk/fashion/build-a-...   \n",
       "refinery29             Velvet material was seen all over the fall run...   \n",
       "vogueIndia             5 designer labels you will always find in alia...   \n",
       "\n",
       "                       avg_word  \n",
       "fashionspotcontent     5.936963  \n",
       "justthedesign          4.988989  \n",
       "mariecuriefashiontext  5.025445  \n",
       "refinery29             5.429397  \n",
       "vogueIndia             4.941884  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def avg_word(sentence):\n",
    "  words = sentence.split()\n",
    "  return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "data_df['avg_word'] = data_df['fashiontext'].apply(lambda x: avg_word(x))\n",
    "data_df[['fashiontext','avg_word']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating number of predefined stopwords in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fashiontext</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fashionspotcontent</th>\n",
       "      <td>\"There are certain staples every wardrobe need...</td>\n",
       "      <td>78521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>justthedesign</th>\n",
       "      <td>Our Reasons To Give Into The Embroidery Trend ...</td>\n",
       "      <td>386838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mariecuriefashiontext</th>\n",
       "      <td>https://www.marieclaire.co.uk/fashion/build-a-...</td>\n",
       "      <td>35925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refinery29</th>\n",
       "      <td>Velvet material was seen all over the fall run...</td>\n",
       "      <td>87841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vogueIndia</th>\n",
       "      <td>5 designer labels you will always find in alia...</td>\n",
       "      <td>397249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             fashiontext  \\\n",
       "fashionspotcontent     \"There are certain staples every wardrobe need...   \n",
       "justthedesign          Our Reasons To Give Into The Embroidery Trend ...   \n",
       "mariecuriefashiontext  https://www.marieclaire.co.uk/fashion/build-a-...   \n",
       "refinery29             Velvet material was seen all over the fall run...   \n",
       "vogueIndia             5 designer labels you will always find in alia...   \n",
       "\n",
       "                       stopwords  \n",
       "fashionspotcontent         78521  \n",
       "justthedesign             386838  \n",
       "mariecuriefashiontext      35925  \n",
       "refinery29                 87841  \n",
       "vogueIndia                397249  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "data_df['stopwords'] = data_df['fashiontext'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "data_df[['fashiontext','stopwords']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating number of digits in text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fashiontext</th>\n",
       "      <th>numerics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fashionspotcontent</th>\n",
       "      <td>\"There are certain staples every wardrobe need...</td>\n",
       "      <td>1847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>justthedesign</th>\n",
       "      <td>Our Reasons To Give Into The Embroidery Trend ...</td>\n",
       "      <td>5823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mariecuriefashiontext</th>\n",
       "      <td>https://www.marieclaire.co.uk/fashion/build-a-...</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refinery29</th>\n",
       "      <td>Velvet material was seen all over the fall run...</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vogueIndia</th>\n",
       "      <td>5 designer labels you will always find in alia...</td>\n",
       "      <td>6848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             fashiontext  \\\n",
       "fashionspotcontent     \"There are certain staples every wardrobe need...   \n",
       "justthedesign          Our Reasons To Give Into The Embroidery Trend ...   \n",
       "mariecuriefashiontext  https://www.marieclaire.co.uk/fashion/build-a-...   \n",
       "refinery29             Velvet material was seen all over the fall run...   \n",
       "vogueIndia             5 designer labels you will always find in alia...   \n",
       "\n",
       "                       numerics  \n",
       "fashionspotcontent         1847  \n",
       "justthedesign              5823  \n",
       "mariecuriefashiontext       411  \n",
       "refinery29                  228  \n",
       "vogueIndia                 6848  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['numerics'] = data_df['fashiontext'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "data_df[['fashiontext','numerics']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating number of Lower case words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fashiontext</th>\n",
       "      <th>lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fashionspotcontent</th>\n",
       "      <td>\"There are certain staples every wardrobe need...</td>\n",
       "      <td>189867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>justthedesign</th>\n",
       "      <td>Our Reasons To Give Into The Embroidery Trend ...</td>\n",
       "      <td>866104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mariecuriefashiontext</th>\n",
       "      <td>https://www.marieclaire.co.uk/fashion/build-a-...</td>\n",
       "      <td>81235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refinery29</th>\n",
       "      <td>Velvet material was seen all over the fall run...</td>\n",
       "      <td>218814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vogueIndia</th>\n",
       "      <td>5 designer labels you will always find in alia...</td>\n",
       "      <td>901664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             fashiontext  \\\n",
       "fashionspotcontent     \"There are certain staples every wardrobe need...   \n",
       "justthedesign          Our Reasons To Give Into The Embroidery Trend ...   \n",
       "mariecuriefashiontext  https://www.marieclaire.co.uk/fashion/build-a-...   \n",
       "refinery29             Velvet material was seen all over the fall run...   \n",
       "vogueIndia             5 designer labels you will always find in alia...   \n",
       "\n",
       "                        lower  \n",
       "fashionspotcontent     189867  \n",
       "justthedesign          866104  \n",
       "mariecuriefashiontext   81235  \n",
       "refinery29             218814  \n",
       "vogueIndia             901664  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['lower'] = data_df['fashiontext'].apply(lambda x: len([x for x in x.split() if x.islower()]))\n",
    "data_df[['fashiontext','lower']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-d204c6f85b4b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-d204c6f85b4b>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Calculating number of Upper case words\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Calculating number of Upper case words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fashiontext</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fashionspotcontent</th>\n",
       "      <td>\"There are certain staples every wardrobe need...</td>\n",
       "      <td>1588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>justthedesign</th>\n",
       "      <td>Our Reasons To Give Into The Embroidery Trend ...</td>\n",
       "      <td>16141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mariecuriefashiontext</th>\n",
       "      <td>https://www.marieclaire.co.uk/fashion/build-a-...</td>\n",
       "      <td>1837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refinery29</th>\n",
       "      <td>Velvet material was seen all over the fall run...</td>\n",
       "      <td>3049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vogueIndia</th>\n",
       "      <td>5 designer labels you will always find in alia...</td>\n",
       "      <td>11441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             fashiontext  \\\n",
       "fashionspotcontent     \"There are certain staples every wardrobe need...   \n",
       "justthedesign          Our Reasons To Give Into The Embroidery Trend ...   \n",
       "mariecuriefashiontext  https://www.marieclaire.co.uk/fashion/build-a-...   \n",
       "refinery29             Velvet material was seen all over the fall run...   \n",
       "vogueIndia             5 designer labels you will always find in alia...   \n",
       "\n",
       "                       upper  \n",
       "fashionspotcontent      1588  \n",
       "justthedesign          16141  \n",
       "mariecuriefashiontext   1837  \n",
       "refinery29              3049  \n",
       "vogueIndia             11441  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['upper'] = data_df['fashiontext'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "data_df[['fashiontext','upper']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning - Removing Punctuations, Links, numbers, non-english words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "def remove_links(webtext):\n",
    "    \n",
    "    tweet = re.sub(r'https:\\S+', '', webtext) # remove http links\n",
    "    tweet = re.sub(r'bit.ly/\\S+', '', webtext) # rempve bitly links\n",
    "    tweet = re.sub(r'//www.\\S+', '', webtext)\n",
    "    tweet = webtext.strip('[link]') # remove [links]\n",
    "    return tweet\n",
    "round0 = lambda x: remove_links(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fashiontext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fashionspotcontent</th>\n",
       "      <td>\"There are certain staples every wardrobe need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>justthedesign</th>\n",
       "      <td>Our Reasons To Give Into The Embroidery Trend ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mariecuriefashiontext</th>\n",
       "      <td>https://www.marieclaire.co.uk/fashion/build-a-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refinery29</th>\n",
       "      <td>Velvet material was seen all over the fall run...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vogueIndia</th>\n",
       "      <td>5 designer labels you will always find in alia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voguefashiontext</th>\n",
       "      <td>//www.vogue.co.uk//fashion/article/guide-to-b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             fashiontext\n",
       "fashionspotcontent     \"There are certain staples every wardrobe need...\n",
       "justthedesign          Our Reasons To Give Into The Embroidery Trend ...\n",
       "mariecuriefashiontext  https://www.marieclaire.co.uk/fashion/build-a-...\n",
       "refinery29             Velvet material was seen all over the fall run...\n",
       "vogueIndia             5 designer labels you will always find in alia...\n",
       "voguefashiontext        //www.vogue.co.uk//fashion/article/guide-to-b..."
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean = pd.DataFrame(data_df.fashiontext.apply(round0))\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_1(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub('\\xa0', ' ', text)\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    \n",
    "    text = re.sub('\\s+', ' ', text) #remove double spacing\n",
    "    text = re.sub('([0-9]+)', '', text) # remove numbers\n",
    "    text = re.sub(\"[^0-9A-Za-z///]\", ' ', text) ##remove non english word\n",
    "    \n",
    "    return text\n",
    "\n",
    "round1 = lambda x: clean_text_1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = pd.DataFrame(data_clean.fashiontext.apply(round1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a second round of cleaning\n",
    "def clean_text_2(text):\n",
    "    '''Get rid of some additional punctuation and non-sensical text that was missed the first time around.'''\n",
    "    text = re.sub('[‘’“”…]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('xa', ' ', text)\n",
    "    text = re.sub('https', ' ', text)\n",
    "    text = re.sub('www', ' ', text)\n",
    "    text = re.sub(r'[^\\w]', ' ', text)\n",
    "    text = re.sub('contactus', ' ', text)\n",
    "    text = re.sub(r'\\b\\w{12,}\\b', '', text) #keeping word with length less than 12\n",
    "    \n",
    "    return text\n",
    "\n",
    "round2 = lambda x: clean_text_2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fashiontext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fashionspotcontent</th>\n",
       "      <td>certain staples every wardrobe needs especiall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>justthedesign</th>\n",
       "      <td>reasons give embroidery trend wear itby margar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mariecuriefashiontext</th>\n",
       "      <td>marieclaire co sustainable wardrobe words ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refinery29</th>\n",
       "      <td>velvet material seen fall runways around luxur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vogueIndia</th>\n",
       "      <td>designer labels find alia bhatt wardrobe viral...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voguefashiontext</th>\n",
       "      <td>vogue co buying watch watcheshow buy watch v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             fashiontext\n",
       "fashionspotcontent     certain staples every wardrobe needs especiall...\n",
       "justthedesign          reasons give embroidery trend wear itby margar...\n",
       "mariecuriefashiontext      marieclaire co sustainable wardrobe words ...\n",
       "refinery29             velvet material seen fall runways around luxur...\n",
       "vogueIndia             designer labels find alia bhatt wardrobe viral...\n",
       "voguefashiontext         vogue co buying watch watcheshow buy watch v..."
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean = pd.DataFrame(data_clean.fashiontext.apply(round2))\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopword removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "data_clean['fashiontext'] = data_clean['fashiontext'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding most occuring words to stopword list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = pd.Series(' '.join(data_clean['fashiontext']).split()).value_counts()[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "stop_words.extend(['like','etc','often','made',\"oh'\",'also','still', 'look', 'one', 'new', 'know','kapoor','thats','two','youre','one','look','like','always','really','well','want','week','dont','back','says','day','something','go','take','even','get','us','made','year','way','make','show','talk','also','time','collection','one','way'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean['fashiontext'] = data_clean['fashiontext'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop_words))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing words occuring rarely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cherubic      1\n",
       "catalytic     1\n",
       "clinks        1\n",
       "benjikahnx    1\n",
       "stuffs        1\n",
       "             ..\n",
       "aza           1\n",
       "poetess       1\n",
       "kunzites      1\n",
       "postponing    1\n",
       "desir         1\n",
       "Length: 100, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.Series(' '.join(data_clean['fashiontext']).split()).value_counts()[-100:]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fashionspotcontent       certain staples every wardrobe needs especiall...\n",
       "justthedesign            reasons give embroidery trend wear itby margar...\n",
       "mariecuriefashiontext    marieclaire co sustainable wardrobe words rosa...\n",
       "refinery29               velvet material seen fall runways around luxur...\n",
       "vogueIndia               designer labels find alia bhatt wardrobe viral...\n",
       "Name: fashiontext, dtype: object"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = list(freq.index)\n",
    "data_clean['fashiontext'] = data_clean['fashiontext'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "data_clean['fashiontext'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer_english = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fashionspotcontent       certain staples every wardrobe needs especiall...\n",
       "justthedesign            reasons give embroidery trend wear itby margar...\n",
       "mariecuriefashiontext    marieclaire co sustainable wardrobe words rosa...\n",
       "refinery29               velvet material seen fall runways around luxur...\n",
       "vogueIndia               designer labels find alia bhatt wardrobe viral...\n",
       "voguefashiontext         vogue co buying watch watcheshow buy watch vog...\n",
       "Name: fashiontext, dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean['fashiontext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean['fashiontext']=data_clean['fashiontext'].apply(lambda x : filter(None,x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean['fashiontext']=data_clean['fashiontext'].apply(lambda x : [stemmer_english.stem(y) for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean['fashiontext']=data_clean['fashiontext'].apply(lambda x : \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean['fashiontext'] = data_clean['fashiontext'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fashionspotcontent       certain stapl everi wardrob need especi come s...\n",
       "justthedesign            reason give embroideri trend wear itbi margare...\n",
       "mariecuriefashiontext    marieclair co sustain wardrob word rosanna fal...\n",
       "refinery29               velvet materi seen fall runway around luxuri c...\n",
       "vogueIndia               design label find alia bhatt wardrob viral bha...\n",
       "voguefashiontext         vogu co buy watch watcheshow buy watch vogu ul...\n",
       "Name: fashiontext, dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean['fashiontext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fashion    18201\n",
       "wear       12339\n",
       "style      12158\n",
       "dress      11004\n",
       "design     10108\n",
       "trend       6880\n",
       "black       6717\n",
       "brand       6330\n",
       "bag         5854\n",
       "work        5827\n",
       "vogu        5713\n",
       "jean        5453\n",
       "white       5260\n",
       "top         4990\n",
       "pair        4768\n",
       "look        4719\n",
       "woman       4697\n",
       "outfit      4484\n",
       "shoe        4153\n",
       "first       4112\n",
       "piec        3998\n",
       "co          3965\n",
       "jacket      3869\n",
       "come        3844\n",
       "love        3842\n",
       "dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.Series(' '.join(data_clean['fashiontext']).split()).value_counts()[:25]\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords Adding Most repeated words 'Fashion', 'wear','style','design'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "stop_words.extend(['like','look','one','new','time','also','first','show','make','way','year','people','made','work','us','get','even','brand','even','take','go','something','day','pair','says','dont','years','think','brands','week','world','best','would','want','really','well','always','see','every','looks','youre','last','trend','many','much','know','kapoor','thats','need','im','instagram','next','photos','perfect','right','theres','around','set','said','going','things','making','never','come','could','since','little','everything','looking','comes','help','different','find','lot','say','another','bhayani','photo','ever','shes','piece','together','shows','seen','home','line','keep','important','house','got','ahead','thing','yet','shared','create','whether','including','without','makes','cant','number','often','theyre','add','give','though','took','try','today','paired','put','already','ready','went','came','moment','started','place','use','doesnt','director','didnt','ive','isnt','times','told','change','become','everyone','youll','family','course','social','actually','might','wanted','khan','image','matching','taking','away','end','based','month','less','ways','especially','anything','known','behind','across','created','free','enough','via','actor','company','met','head','media','getting','though','saw','almost','using','site','picks','x','scroll','images','must','instead','read','second','felt','choice','quite','worked','space','nothing','bring','according','options','means','ones','school','later','choose','among','done','able','called','someone','youve','let','pick','tells','wasnt','ago','person','ensemble','whats','given','occasion','kareena','open','link','form','sonam','explains','version','heres','goes','taken','takes','simply','ahuja','definitely','fashion','wear','style','design','trend'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fashiontext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fashionspotcontent</th>\n",
       "      <td>certain stapl everi wardrob especi summer talk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>justthedesign</th>\n",
       "      <td>reason embroideri itbi margaret wright recogni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mariecuriefashiontext</th>\n",
       "      <td>marieclair co sustain wardrob word rosanna fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refinery29</th>\n",
       "      <td>velvet materi fall runway luxuri colour versat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vogueIndia</th>\n",
       "      <td>label alia bhatt wardrob viral may statement i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voguefashiontext</th>\n",
       "      <td>vogu co buy watch watcheshow buy watch vogu ul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             fashiontext\n",
       "fashionspotcontent     certain stapl everi wardrob especi summer talk...\n",
       "justthedesign          reason embroideri itbi margaret wright recogni...\n",
       "mariecuriefashiontext  marieclair co sustain wardrob word rosanna fal...\n",
       "refinery29             velvet materi fall runway luxuri colour versat...\n",
       "vogueIndia             label alia bhatt wardrob viral may statement i...\n",
       "voguefashiontext       vogu co buy watch watcheshow buy watch vogu ul..."
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean['fashiontext'] = data_clean['fashiontext'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop_words))\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buchenwald    1\n",
       "larroud       1\n",
       "schonfeld     1\n",
       "hamersveld    1\n",
       "vinoodhfor    1\n",
       "             ..\n",
       "bandiera      1\n",
       "ugra          1\n",
       "bano          1\n",
       "cousu         1\n",
       "catchup       1\n",
       "Length: 200, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.Series(' '.join(data_clean['fashiontext']).split()).value_counts()[-200:]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fashionspotcontent       certain stapl everi wardrob especi summer talk...\n",
       "justthedesign            reason embroideri itbi margaret wright recogni...\n",
       "mariecuriefashiontext    marieclair co sustain wardrob word rosanna fal...\n",
       "refinery29               velvet materi fall runway luxuri colour versat...\n",
       "vogueIndia               label alia bhatt wardrob viral may statement i...\n",
       "Name: fashiontext, dtype: object"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = list(freq.index)\n",
    "data_clean['fashiontext'] = data_clean['fashiontext'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "data_clean['fashiontext'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df.to_pickle(\"webblogcorpus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_clean.to_pickle(\"finalclean2withfashionweardress.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating 'Document Term Matrix' using 'TF-IDF' and 'Countvectorizer' also known as BoW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abbasi</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abbot</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abet</th>\n",
       "      <th>abey</th>\n",
       "      <th>abject</th>\n",
       "      <th>...</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zircon</th>\n",
       "      <th>zirconia</th>\n",
       "      <th>zo</th>\n",
       "      <th>zoa</th>\n",
       "      <th>zodiac</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fashionspotcontent</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.001504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>justthedesign</th>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00093</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.003303</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.003336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mariecuriefashiontext</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refinery29</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.00066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vogueIndia</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.007500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voguefashiontext</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 9385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             aa     aback   abandon    abbasi     abbey  \\\n",
       "fashionspotcontent     0.000000  0.000000  0.001086  0.000000  0.000000   \n",
       "justthedesign          0.000465  0.000381  0.001342  0.000381  0.000238   \n",
       "mariecuriefashiontext  0.000000  0.000000  0.000810  0.000000  0.004675   \n",
       "refinery29             0.000000  0.000000  0.000098  0.000000  0.000113   \n",
       "vogueIndia             0.000000  0.000179  0.001552  0.000179  0.000560   \n",
       "voguefashiontext       0.000000  0.000000  0.001169  0.000000  0.002024   \n",
       "\n",
       "                         abbot   abdomen      abet     abey    abject  ...  \\\n",
       "fashionspotcontent     0.00000  0.000000  0.000000  0.00000  0.000000  ...   \n",
       "justthedesign          0.00000  0.000465  0.000000  0.00093  0.000465  ...   \n",
       "mariecuriefashiontext  0.00000  0.000000  0.000000  0.00000  0.000000  ...   \n",
       "refinery29             0.00066  0.000000  0.000000  0.00000  0.000000  ...   \n",
       "vogueIndia             0.00000  0.000000  0.000218  0.00000  0.000000  ...   \n",
       "voguefashiontext       0.00000  0.000000  0.000000  0.00000  0.000000  ...   \n",
       "\n",
       "                         zipper    zircon  zirconia        zo       zoa  \\\n",
       "fashionspotcontent     0.002506  0.000000  0.000000  0.001754  0.000489   \n",
       "justthedesign          0.001787  0.000233  0.000138  0.001787  0.000000   \n",
       "mariecuriefashiontext  0.000000  0.000000  0.002166  0.000000  0.000000   \n",
       "refinery29             0.001690  0.000000  0.000000  0.005295  0.000000   \n",
       "vogueIndia             0.001455  0.000000  0.000259  0.002015  0.000000   \n",
       "voguefashiontext       0.002699  0.000000  0.001563  0.000675  0.000000   \n",
       "\n",
       "                         zodiac     zombi      zone       zoo      zoom  \n",
       "fashionspotcontent     0.000580  0.000339  0.001737  0.000677  0.001504  \n",
       "justthedesign          0.000690  0.000805  0.003303  0.000322  0.003336  \n",
       "mariecuriefashiontext  0.000000  0.000000  0.002431  0.000000  0.010286  \n",
       "refinery29             0.000000  0.000000  0.000683  0.000000  0.000000  \n",
       "vogueIndia             0.002074  0.000303  0.002716  0.000151  0.007500  \n",
       "voguefashiontext       0.000781  0.000000  0.002923  0.000000  0.006073  \n",
       "\n",
       "[6 rows x 9385 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tfidf = vectorizer.fit_transform(data_clean.fashiontext)\n",
    "data_tdf = pd.DataFrame(data_tfidf.toarray(), columns=vectorizer.get_feature_names())\n",
    "data_tdf.index = data_clean.index\n",
    "data_tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abbasi</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abbot</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abet</th>\n",
       "      <th>abey</th>\n",
       "      <th>abject</th>\n",
       "      <th>...</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zircon</th>\n",
       "      <th>zirconia</th>\n",
       "      <th>zo</th>\n",
       "      <th>zoa</th>\n",
       "      <th>zodiac</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fashionspotcontent</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>justthedesign</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mariecuriefashiontext</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refinery29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vogueIndia</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voguefashiontext</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 9385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       aa  aback  abandon  abbasi  abbey  abbot  abdomen  \\\n",
       "fashionspotcontent      0      0        5       0      0      0        0   \n",
       "justthedesign           2      2       13       2      2      0        2   \n",
       "mariecuriefashiontext   0      0        1       0      5      0        0   \n",
       "refinery29              0      0        1       0      1      3        0   \n",
       "vogueIndia              0      1       16       1      5      0        0   \n",
       "voguefashiontext        0      0        2       0      3      0        0   \n",
       "\n",
       "                       abet  abey  abject  ...  zipper  zircon  zirconia  zo  \\\n",
       "fashionspotcontent        0     0       0  ...      10       0         0   7   \n",
       "justthedesign             0     4       2  ...      15       1         1  15   \n",
       "mariecuriefashiontext     0     0       0  ...       0       0         2   0   \n",
       "refinery29                0     0       0  ...      15       0         0  47   \n",
       "vogueIndia                1     0       0  ...      13       0         2  18   \n",
       "voguefashiontext          0     0       0  ...       4       0         2   1   \n",
       "\n",
       "                       zoa  zodiac  zombi  zone  zoo  zoom  \n",
       "fashionspotcontent       1       2      1     8    2     6  \n",
       "justthedesign            0       5      5    32    2    28  \n",
       "mariecuriefashiontext    0       0      0     3    0    11  \n",
       "refinery29               0       0      0     7    0     0  \n",
       "vogueIndia               0      16      2    28    1    67  \n",
       "voguefashiontext         0       1      0     5    0     9  \n",
       "\n",
       "[6 rows x 9385 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "data_cv = cv.fit_transform(data_clean.fashiontext)\n",
    "data_matrix = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "data_matrix.index = data_clean.index\n",
    "data_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_tdf.to_pickle(\"documenttermmatrixtdf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#pickle.dump(cv, open(\"cv.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
